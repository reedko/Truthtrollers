import { orchestrateScraping } from "./orchestrateScraping";
import createTask from "./createTask";
import { TaskData, Lit_references } from "../entities/Task";

const EXTENSION_ID = "hfihldigngpdcbmedijohjdcjppdfepj";
const BASE_URL = process.env.REACT_APP_BASE_URL || "http://localhost:5001";

export const scrapeContent = async (
  url: string,
  content_name: string,
  contentType: "task" | "reference",
  taskContentId?: string
): Promise<string | null> => {
  console.log(`ðŸ” Scraping ${contentType}: ${url}`);

  try {
    let contentData: TaskData | null = null;

    // âœ… Step 1: Pre-define contentData for non-scrapable references
    if (contentType === "reference" && isNonScrapable(url)) {
      console.warn("ðŸš« Non-scrapable file detected, skipping scraping:", url);
      contentData = {
        url,
        content_name: content_name || "Untitled Reference",
        content_type: "reference",
        media_source: "Unknown",
        assigned: "unassigned",
        progress: "Unassigned",
        users: "",
        details:
          "This reference is a non-scrapable file (e.g., PDF, audio, video).",
        topic: "general",
        subtopics: ["general", ""],
        thumbnail: `${BASE_URL}/assets/images/content/document-placeholder.png`, // âœ… Default document icon
        iconThumbnailUrl: null,
        authors: [],
        content: [],
        publisherName: null,
        Claims: [],
        taskContentId: taskContentId || null, // âœ… Ensuring the task reference is linked
      };
    }

    // âœ… Step 2: Scrape metadata (only if not nonScrapable)
    if (!contentData) {
      contentData = await orchestrateScraping(url, content_name, contentType);
    }

    if (!contentData) {
      console.error("ðŸš¨ Failed to obtain contentData for:", url);
      return null;
    }
    // âœ… Ensure taskContentId is set for references
    // âœ… Ensure taskContentId is assigned for scrapable references
    if (!contentData.taskContentId) {
      contentData.taskContentId = taskContentId || null;
    }

    // âœ… Step 3: Save content to DB (handles duplicate detection internally)
    console.log("ðŸ“Ž Saving content to DB:", contentData);
    const contentId = await createTask(contentData);
    if (!contentId) {
      console.error("âŒ Failed to create content:", url);
      return "createTaskFAIL";
    }
    console.log(`âœ… Content created with ID: ${contentId}`);

    // âœ… Step 4: Store references separately (only for tasks)
    const references: Lit_references[] =
      contentType === "task" ? [...contentData.content] : [];

    // âœ… If this is the first (main) task, store taskContentId for linking references
    if (contentType === "task" && !taskContentId) {
      taskContentId = contentId;
    }

    // âœ… Step 5: Recursively process references (only for tasks)
    if (contentType === "task" && references.length > 0) {
      for (const reference of references) {
        console.log(
          "ðŸ”— Scraping reference:",
          reference.url,
          "Title:",
          reference.content_name
        );

        await scrapeContent(
          reference.url,
          reference.content_name || "",
          "reference",
          taskContentId
        );
      }
    }

    return contentId;
  } catch (err) {
    console.error("âŒ Error during content scraping:", err);
    return null;
  }
};

// âœ… Function to check if a URL is non-scrapable (PDFs, audio, video, etc.)
const isNonScrapable = (url: string) => {
  const nonScrapableFileTypes = [
    ".pdf",
    ".zip",
    ".exe",
    ".doc",
    ".ppt",
    ".xls", // Documents & archives
    ".mp3",
    ".wav",
    ".ogg",
    ".flac", // Audio
    ".mp4",
    ".avi",
    ".mov",
    ".mkv",
    ".webm", // Video
  ];
  return nonScrapableFileTypes.some((ext) => url.toLowerCase().endsWith(ext));
};
